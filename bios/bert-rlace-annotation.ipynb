{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier, LinearRegression, Lasso, Ridge\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sn\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "from sklearn.manifold import TSNE\n",
    "import tqdm\n",
    "import copy\n",
    "from sklearn.svm import LinearSVC \n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import torch\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cluster\n",
    "from sklearn import neural_network\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import warnings\n",
    "import argparse\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from collections import defaultdict\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Experiment Procedure\n",
    "The R-LACE experiment on BERT proceeds as follows:\n",
    "\n",
    "- Finetune BERT to classify professions (BERT-finetuned)\n",
    "\t- Also, finetune BERT with two types of adversarial gender removal training (BERT-adv and BERT-mlp-adv) to use as a baseline\n",
    "\n",
    "- Run Alg. 1 on representations\n",
    "\t- Take representations in last layer of BERT at the [CLS] token\n",
    "\t- Reduce dimensionality of representations to 300 using PCA\n",
    "\t- Run Alg. 1 with 5 random initializations\n",
    "\t\n",
    "- Finetune linear profession-classification head after the projection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune BERT\n",
    "In this step, BERT is fine-tuned to classify professions given a biographical text prompt. The experimenters also train two varieties of adversarial heads to predict gender where the gradient is reversed, which are used as baselines in the concept-removal experiment. Details can be found in the `finetune.py` file.\n",
    "\n",
    "The resulting state dictionaries are saved in the `models` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 finetune.py --run_id 0 --device 0 --adv 0 --opt sgd &\n",
    "!python3 finetune.py --run_id 1 --device 1 --adv 0 --opt sgd &\n",
    "!python3 finetune.py --run_id 2 --device 2 --adv 0 --opt sgd &\n",
    "!python3 finetune.py --run_id 3 --device 3 --adv 0 --opt sgd\n",
    "!sleep 10\n",
    "!python3 finetune.py --run_id 4 --device 0 --adv 0 --opt sgd &\n",
    "\n",
    "!python3 finetune.py --run_id 0 --device 1 --adv 1 --opt sgd &\n",
    "!python3 finetune.py --run_id 1 --device 2 --adv 1 --opt sgd &\n",
    "!python3 finetune.py --run_id 2 --device 3 --adv 1 --opt sgd\n",
    "!sleep 10\n",
    "!python3 finetune.py --run_id 3 --device 0 --adv 1 --opt sgd &\n",
    "!python3 finetune.py --run_id 4 --device 1 --adv 1 --opt sgd &\n",
    "\n",
    "!python3 finetune.py --run_id 0 --device 2 --adv 1 --mlp_adv 1 --opt sgd &\n",
    "!python3 finetune.py --run_id 1 --device 3 --adv 1 --mlp_adv 1 --opt sgd\n",
    "!sleep 10\n",
    "!python3 finetune.py --run_id 2 --device 0 --adv 1 --mlp_adv 1 --opt sgd &\n",
    "!python3 finetune.py --run_id 3 --device 1 --adv 1 --mlp_adv 1 --opt sgd &\n",
    "!python3 finetune.py --run_id 4 --device 2 --adv 1 --mlp_adv 1 --opt sgd\n",
    "!sleep 100\n",
    "!python3 encode.py --device 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode & Save Representations From Final Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import tqdm\n",
    "import copy\n",
    "import torch\n",
    "\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import argparse\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bios(group):\n",
    "    \"\"\"Load bios data from pickle file.\n",
    "    \n",
    "    Args:\n",
    "        group (str): train, dev, or test.\n",
    "\n",
    "    Returns:\n",
    "        list: List of bios texts.\n",
    "    \"\"\"\n",
    "    with open(\n",
    "        \"/media/curttigges/project-files/datasets/bios/bios_data/{}.pickle\".format(\n",
    "            group\n",
    "        ),\n",
    "        \"rb\",\n",
    "    ) as f:\n",
    "        bios_data = pickle.load(f)\n",
    "        txts = [d[\"hard_text_untokenized\"] for d in bios_data]\n",
    "\n",
    "    return txts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(bert, tokenizer, texts):\n",
    "    \"\"\"Run a list of texts through BERT and return the hidden state at the classification token position of the last layer.\n",
    "\n",
    "    The function first tokenizes the texts, then runs them through BERT, and finally returns the hidden state at the \n",
    "    classification token position of the last layer.\n",
    "\n",
    "    Args:\n",
    "        bert (BertModel): A BERT model.\n",
    "        texts (list): A list of texts to encode.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A numpy array of shape (len(texts), bert_hidden_size) containing the BERT embeddings for the\n",
    "        classification token of each text.\n",
    "    \"\"\"\n",
    "    all_H = []\n",
    "    bert.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        print(\"Encoding...\")\n",
    "        batch_size = 100\n",
    "        pbar = tqdm.tqdm(range(len(texts)), ascii=True)\n",
    "\n",
    "        for i in range(0, len(texts) - batch_size, batch_size):\n",
    "\n",
    "            batch_texts = texts[i : i + batch_size]\n",
    "\n",
    "            batch_encoding = tokenizer.batch_encode_plus(\n",
    "                batch_texts, padding=True, max_length=512, truncation=True\n",
    "            )\n",
    "            input_ids, token_type_ids, attention_mask = (\n",
    "                batch_encoding[\"input_ids\"],\n",
    "                batch_encoding[\"token_type_ids\"],\n",
    "                batch_encoding[\"attention_mask\"],\n",
    "            )\n",
    "            input_ids = torch.tensor(input_ids).to(device)\n",
    "            token_type_ids = torch.tensor(token_type_ids).to(device)\n",
    "            attention_mask = torch.tensor(attention_mask).to(device)\n",
    "            H = bert(\n",
    "                input_ids=input_ids,\n",
    "                token_type_ids=token_type_ids,\n",
    "                attention_mask=attention_mask,\n",
    "            )[\"pooler_output\"]\n",
    "            assert len(H.shape) == 2\n",
    "            all_H.append(H.detach().cpu().numpy())\n",
    "\n",
    "            pbar.update(batch_size)\n",
    "\n",
    "        remaining = texts[(len(texts) // batch_size) * batch_size :]\n",
    "        print(len(remaining))\n",
    "        if len(remaining) > 0:\n",
    "            batch_encoding = tokenizer.batch_encode_plus(\n",
    "                remaining, padding=True, max_length=512, truncation=True\n",
    "            )\n",
    "            input_ids, token_type_ids, attention_mask = (\n",
    "                batch_encoding[\"input_ids\"],\n",
    "                batch_encoding[\"token_type_ids\"],\n",
    "                batch_encoding[\"attention_mask\"],\n",
    "            )\n",
    "            input_ids = torch.tensor(input_ids).to(device)\n",
    "            token_type_ids = torch.tensor(token_type_ids).to(device)\n",
    "            attention_mask = torch.tensor(attention_mask).to(device)\n",
    "            H = bert(\n",
    "                input_ids=input_ids,\n",
    "                token_type_ids=token_type_ids,\n",
    "                attention_mask=attention_mask,\n",
    "            )[\"pooler_output\"]\n",
    "            assert len(H.shape) == 2\n",
    "            all_H.append(H.detach().cpu().numpy())\n",
    "\n",
    "    H_np = np.concatenate(all_H)\n",
    "    assert len(H_np.shape) == 2\n",
    "    assert len(H_np) == len(texts)\n",
    "    return H_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\"This script runs the BIOS prompts through fine-tuned BERT and saves the output of the residual stream (the final\n",
    "    hidden state) at the classification token position to disk.\n",
    "    \"\"\"\n",
    "    random.seed(0)\n",
    "    np.random.seed(0)\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"An argparse example\")\n",
    "    parser.add_argument(\"--device\", type=int, default=-1, required=False)\n",
    "    parser.add_argument(\"--run_id\", type=int, default=-1, required=False)\n",
    "    args = parser.parse_args()\n",
    "    device = \"cpu\" if args.device == -1 else \"cuda:{}\".format(args.device)\n",
    "    print(device)\n",
    "\n",
    "    # Load BERT\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "    bert.to(device)\n",
    "    bert.eval()\n",
    "    rand_seed = args.run_id\n",
    "\n",
    "    # Make directories\n",
    "    if not os.path.exists(\"encodings\"):\n",
    "        os.makedirs(\"encodings\")\n",
    "    if not os.path.exists(\"encodings/mlp-adv\"):\n",
    "        os.makedirs(\"encodings/mlp-adv\")\n",
    "    if not os.path.exists(\"encodings/linear-adv\"):\n",
    "        os.makedirs(\"encodings/linear-adv\")\n",
    "    if not os.path.exists(\"encodings/no-adv\"):\n",
    "        os.makedirs(\"encodings/no-adv\")\n",
    "\n",
    "    # Loop to load random set of BERT parameters and encode the data\n",
    "    for finetuning_type in [\"adv\", \"mlp_adv\", \"not-adv\"]:\n",
    "        for rand_seed in range(5):\n",
    "            for mode in [\"train\", \"dev\", \"test\"]:\n",
    "\n",
    "                txts = load_bios(mode)\n",
    "                txts = txts[:]\n",
    "\n",
    "                if finetuning_type == \"adv\":\n",
    "                    print(\"Loading adv\")\n",
    "                    bert_params = torch.load(\n",
    "                        \"models/linear-adv/bert_{}.pt\".format(rand_seed)\n",
    "                    )\n",
    "                elif finetuning_type == \"mlp_adv\":\n",
    "                    print(\"Loading MLP adv\")\n",
    "                    bert_params = torch.load(\n",
    "                        \"models/mlp-adv/bert_{}.pt\".format(rand_seed)\n",
    "                    )\n",
    "                else:\n",
    "                    bert_params = torch.load(\n",
    "                        \"models/no-adv/bert_{}.pt\".format(rand_seed)\n",
    "                    )\n",
    "\n",
    "                bert.load_state_dict(bert_params)\n",
    "                # Get model output\n",
    "                H = encode(bert, tokenizer, txts)\n",
    "                # Save model output\n",
    "                print(H.shape)\n",
    "                path = (\n",
    "                    \"encodings/linear-adv/{}_{}_cls.npy\".format(mode, rand_seed)\n",
    "                    if finetuning_type == \"adv\"\n",
    "                    else \"encodings/mlp-adv/{}_{}_cls.npy\".format(mode, rand_seed)\n",
    "                    if finetuning_type == \"mlp_adv\"\n",
    "                    else \"encodings/no-adv/{}_{}_cls.npy\".format(mode, rand_seed)\n",
    "                )\n",
    "                np.save(path, H)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run R-LACE on Representations\n",
    "The next step is to perform R-LACE on the hidden states of the classification tokens in order to generate a projection matrix that will remove the gender representation directions. Before doing so, the experimenters run PCA on the hidden dimensions and reduce them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"/../\")\n",
    "\n",
    "from debias import get_debiasing_projection, get_rowspace_projection\n",
    "\n",
    "from classifier import CovMaximizer\n",
    "from sklearn.linear_model import SGDClassifier, LinearRegression, Lasso, Ridge\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sn\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "from sklearn.manifold import TSNE\n",
    "import tqdm\n",
    "import copy\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import torch\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from rlace import solve_adv_game\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cluster\n",
    "from sklearn import neural_network\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import warnings\n",
    "import argparse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "ranks = [1,4,8,16,32,50,64,100]\n",
    "rlace_projs = defaultdict(dict)\n",
    "inlp_projs = defaultdict(dict)\n",
    "finetune_mode = \"no-adv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def set_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "def load_bios(group, finetune_mode, seed=None):\n",
    "    \"\"\"Loads the encoded classification tokens for a given group (train, dev, test) and finetuning mode (no-adv, mlp-adv, \n",
    "        linear-adv)\n",
    "\n",
    "    Args:\n",
    "        group (str): train, dev, or test\n",
    "        finetune_mode (str): no-adv, mlp-adv, linear-adv\n",
    "        seed (int, optional): Random seed used for finetuning. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (X, Y, professions, txts, bios_data)\n",
    "    \"\"\"\n",
    "    if finetune_mode not in [\"no-adv\", \"mlp-adv\", \"linear-adv\"]:\n",
    "        X = np.load(\"bios_data/{}_cls.npy\".format(group))\n",
    "    else:\n",
    "        X = np.load(\"encodings/{}/{}_{}_cls.npy\".format(finetune_mode, group, seed))\n",
    "    with open(\"bios_data/{}.pickle\".format(group), \"rb\") as f:\n",
    "        bios_data = pickle.load(f)\n",
    "        Y = np.array([1 if d[\"g\"] == \"f\" else 0 for d in bios_data])\n",
    "        professions = np.array([d[\"p\"] for d in bios_data])\n",
    "        txts = [d[\"hard_text_untokenized\"] for d in bios_data]\n",
    "        random.seed(0)\n",
    "        np.random.seed(0)\n",
    "        X, Y, professions, txts, bios_data = sklearn.utils.shuffle(X, Y, professions, txts, bios_data)\n",
    "        X = X[:]\n",
    "        Y = Y[:]\n",
    "\n",
    "    return X, Y, txts, professions, bios_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Encoded Classification Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, txts, professions, bios_data = load_bios(\"train\", finetune_mode, args.run_id)\n",
    "X, y = X[:100000], y[:100000]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"pca\"):\n",
    "    os.makedirs(\"pca\")\n",
    "pca = PCA(random_state=args.run_id, n_components=300)\n",
    "pca.fit(X)\n",
    "with open(\"pca/pca_{}_{}.pickle\".format(finetune_mode, args.run_id), \"wb\") as f:\n",
    "    pickle.dump(pca, f)\n",
    "X = pca.transform(X)\n",
    "\n",
    "X_dev, y_dev, txts_dev, professions_dev, bios_data_dev = load_bios(\"dev\", finetune_mode, args.run_id)\n",
    "X_dev = pca.transform(X_dev)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R-LACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders to store results and plots\n",
    "for random_run in [args.run_id]:\n",
    "    os.makedirs(\"plots/original/pca/run={}\".format(random_run), exist_ok=True)\n",
    "    os.makedirs(\"plots/original/tsne/run={}\".format(random_run), exist_ok=True)\n",
    "    os.makedirs(\"plots/inlp/pca/run={}\".format(random_run), exist_ok=True)\n",
    "    os.makedirs(\"plots/inlp/tsne/run={}\".format(random_run), exist_ok=True)\n",
    "    os.makedirs(\"plots/rlace/pca/run={}\".format(random_run), exist_ok=True)\n",
    "    os.makedirs(\"plots/rlace/tsne/run={}\".format(random_run), exist_ok=True)\n",
    "    os.makedirs(\"interim/rlace/run={}\".format(random_run), exist_ok=True)\n",
    "    os.makedirs(\"interim/inlp/run={}\".format(random_run), exist_ok=True)\n",
    "\n",
    "    os.makedirs(\"plots/{}/original/pca/run={}\".format(finetune_mode, random_run), exist_ok=True)\n",
    "    os.makedirs(\"plots/{}/original/tsne/run={}\".format(finetune_mode, random_run), exist_ok=True)\n",
    "    os.makedirs(\"plots/{}/inlp/pca/run={}\".format(finetune_mode, random_run), exist_ok=True)\n",
    "    os.makedirs(\"plots/{}/inlp/tsne/run={}\".format(finetune_mode, random_run), exist_ok=True)\n",
    "    os.makedirs(\"plots/{}/rlace/pca/run={}\".format(finetune_mode, random_run), exist_ok=True)\n",
    "    os.makedirs(\"plots/{}/rlace/tsne/run={}\".format(finetune_mode, random_run), exist_ok=True)\n",
    "    os.makedirs(\"interim/{}/rlace/run={}\".format(finetune_mode, random_run), exist_ok=True)\n",
    "    os.makedirs(\"interim/{}/inlp/run={}\".format(finetune_mode, random_run), exist_ok=True)\n",
    "\n",
    "    set_seeds(random_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up optimizers and result dictionaries\n",
    "Ps_rlace, accs_rlace = {}, {}\n",
    "\n",
    "optimizer_class = torch.optim.SGD\n",
    "optimizer_params_P = {\"lr\": 0.005, \"weight_decay\": 1e-4, \"momentum\": 0.0}\n",
    "optimizer_params_predictor = {\"lr\": 0.005, \"weight_decay\": 1e-5, \"momentum\": 0.9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run RLACE for each rank\n",
    "for rank in ranks:\n",
    "\n",
    "    output = solve_adv_game(X, y, X, y, rank=rank, device=device, out_iters=60000,\n",
    "                                optimizer_class=optimizer_class, optimizer_params_P=optimizer_params_P,\n",
    "                                optimizer_params_predictor=optimizer_params_predictor, epsilon=0.002,\n",
    "                                batch_size=256)\n",
    "\n",
    "    P = output[\"P\"]\n",
    "    Ps_rlace[rank] = P\n",
    "    accs_rlace[rank] = output[\"score\"]\n",
    "\n",
    "    # Save resulting projection matrices\n",
    "    with open(\"interim/{}/rlace/run={}/Ps_rlace.pickle\".format(finetune_mode, random_run), \"wb\") as f:\n",
    "        pickle.dump((Ps_rlace, accs_rlace), f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply R-LACE Projection to Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier, LinearRegression, Lasso, Ridge\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sn\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "from sklearn.manifold import TSNE\n",
    "import tqdm\n",
    "import copy\n",
    "from sklearn.svm import LinearSVC \n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import torch\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cluster\n",
    "from sklearn import neural_network\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import warnings\n",
    "import argparse\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from collections import defaultdict\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bios(group):\n",
    "    \"\"\"Loads the bios data for the given group.\n",
    "    \n",
    "    Args:\n",
    "        group (str): group (e.g. \"all\", \"f\", \"m\")\n",
    "\n",
    "    Returns:\n",
    "        z (np.array): gender labels\n",
    "        txts (list): biographies without gendered pronouns/names\n",
    "        professions (np.array): profession labels\n",
    "        bios_data (list): bios data\n",
    "    \"\"\"\n",
    "    with open(\"bios_data/{}.pickle\".format(group), \"rb\") as f:\n",
    "        bios_data = pickle.load(f)\n",
    "        z = np.array([1 if d[\"g\"]==\"f\" else 0 for d in bios_data]) # gender labels\n",
    "        professions = np.array([d[\"p\"] for d in bios_data]) # profession labels\n",
    "        txts = [d[\"hard_text_untokenized\"] for d in bios_data] # biographies without gendered pronouns/names\n",
    "        \n",
    "    return z,txts,professions,bios_data\n",
    "\n",
    "def load_bios_representations(group, finetune_mode, seed=0):\n",
    "    \"\"\"Loads the encoded final-layer representations of the classification tokens for the given group, finetune mode and \n",
    "        seed. Also performs PCA on the representations, as was done in training.\n",
    "    \n",
    "    Args:\n",
    "        group (str): group (e.g. \"all\", \"f\", \"m\")\n",
    "        finetune_mode (str): finetune mode (e.g. \"freezed\", \"finetuned\")\n",
    "        seed (int, optional): random seed. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        X (np.array): encoded final-layer representations of the classification tokens\n",
    "    \"\"\"\n",
    "    if finetune_mode == \"freezed\": # only 1 random seed for the pretrained bert\n",
    "        X = np.load(\"encodings//{}/{}_cls.npy\".format(finetune_mode,group))\n",
    "    else:\n",
    "        X = np.load(\"encodings/{}/{}_{}_cls.npy\".format(finetune_mode, group, seed))\n",
    "    \n",
    "    # perform PCA - as was done in training\n",
    "    with open(\"pca/pca_{}_{}.pickle\".format(finetune_mode, seed), \"rb\") as f:\n",
    "        pca = pickle.load(f)\n",
    "    X = pca.transform(X)\n",
    "    \n",
    "    # return transformed X\n",
    "    return X\n",
    "\n",
    "def load_projections(proj_type, finetune_mode, seed=0):\n",
    "    \"\"\"Load the projection matrices for the given projection type and finetune mode\n",
    "\n",
    "    Args:\n",
    "        proj_type (str): projection type (e.g. \"inlp\", \"rlace\")\n",
    "        finetune_mode (str): finetune mode (e.g. \"freezed\", \"finetuned\")\n",
    "        seed (int, optional): random seed. Defaults to 0.\n",
    "    \"\"\"\n",
    "    with open(\"interim/{}/{}/run={}/Ps_{}.pickle\".format(finetune_mode,proj_type,seed,proj_type), \"rb\") as f:\n",
    "        rank2P = pickle.load(f)\n",
    "        return rank2P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load bios data\n",
    "z_train,txts_train,professions_train,train = load_bios(\"train\")\n",
    "z_test,txts_test,professions_test,test = load_bios(\"test\")\n",
    "z_dev,txts_dev,professions_dev,dev = load_bios(\"dev\")\n",
    "\n",
    "# Load encoded representations\n",
    "if False and os.path.exists(\"analysis/\") and os.path.exists(\"analysis/mode2x.pickle\") and os.path.exists(\"analysis/mode2p.pickle\"):\n",
    "    with open(\"analysis/mode2p.pickle\", \"rb\") as f:\n",
    "        mode2p = pickle.load(f)\n",
    "    with open(\"analysis/mode2x.pickle\", \"rb\") as f:\n",
    "        mode2x = pickle.load(f)\n",
    "\n",
    "else:\n",
    "    if not os.path.exists(\"analysis\"): os.mkdir(\"analysis\")\n",
    "    mode2x = defaultdict(dict)\n",
    "    mode2p = defaultdict(dict)\n",
    "\n",
    "    for mode in [\"freezed\", \"linear-adv\", \"mlp-adv\", \"no-adv\"]:\n",
    "     \n",
    "        for group in [\"train\", \"dev\", \"test\"]:\n",
    "            mode2x[mode][group] = {}      \n",
    "            num_seeds = 1 if mode == \"freezed\" else 5\n",
    "        \n",
    "            for seed in range(num_seeds):\n",
    "                print(mode, group, seed)     \n",
    "                X = load_bios_representations(group, mode, seed=seed)\n",
    "                    \n",
    "                mode2x[mode][group][seed] = X\n",
    "                mode2p[mode][seed] = {} \n",
    "                for projtype in [\"rlace\", \"inlp\"]:\n",
    "                    rank2P = load_projections(projtype, mode, seed=seed)\n",
    "                    mode2p[mode][seed][projtype] = rank2P\n",
    "                \n",
    "            \n",
    "    with open(\"analysis/mode2x.pickle\", \"wb\") as f:\n",
    "        pickle.dump(mode2x, f)\n",
    "    with open(\"analysis/mode2p.pickle\", \"wb\") as f:\n",
    "        pickle.dump(mode2p, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune Profession and Gender Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"analysis/mode2x.pickle\", \"rb\") as f:\n",
    "        mode2x = pickle.load(f)\n",
    "with open(\"analysis/mode2p.pickle\", \"rb\") as f:\n",
    "        mode2p = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(X,y,X_dev, y_dev, X_test,y_test):\n",
    "    \"\"\"Trains a classifier on the given data and returns the classifier and its accuracy on the dev and test sets.\n",
    "\n",
    "    Args:\n",
    "        X (np.array): training data\n",
    "        y (np.array): training labels\n",
    "        X_dev (np.array): dev data\n",
    "        y_dev (np.array): dev labels\n",
    "        X_test (np.array): test data\n",
    "        y_test (np.array): test labels\n",
    "\n",
    "    Returns:\n",
    "        clf (sklearn classifier): trained classifier\n",
    "        score_dev (float): accuracy on dev set\n",
    "        score_test (float): accuracy on test set\n",
    "    \"\"\"\n",
    "    random.seed(0)\n",
    "    np.random.seed(0)\n",
    "\n",
    "#     clf = SGDClassifier(loss=\"log\", fit_intercept=True,  max_iter=3, tol = 0.1*1e-3,n_iter_no_change=1,\n",
    "#                            n_jobs=32,alpha=1e-4)\n",
    "    clf = LogisticRegression(warm_start = True, penalty = 'l2',\n",
    "                        solver = \"saga\", multi_class = 'multinomial', fit_intercept = True,\n",
    "                        verbose = 5, n_jobs = 64, random_state = 1, max_iter = 10)\n",
    "    \n",
    "    clf.fit(X,y)\n",
    "    score_dev = clf.score(X_dev,y_dev)\n",
    "    score_test = clf.score(X_test, y_test)\n",
    "    \n",
    "    return clf, score_dev, score_test\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "prof_clfs = defaultdict(dict)\n",
    "gender_clfs = defaultdict(dict)\n",
    "\n",
    "for mode in [\"freezed\", \"linear-adv\", \"mlp-adv\", \"no-adv\"]:\n",
    "    num_seeds = 1 if mode == \"freezed\" else 5\n",
    "    for seed in range(num_seeds):\n",
    "        prof_clfs[mode][seed] = dict()\n",
    "        gender_clfs[mode][seed] = dict()\n",
    "        print(\"============================\")\n",
    "        print(\"mode:\", mode, \"seed:\", seed)\n",
    "        for do_projection in [False, True]:\n",
    "            \n",
    "            \n",
    "            \n",
    "            X_train = mode2x[mode][\"train\"][seed]\n",
    "            X_dev = mode2x[mode][\"dev\"][seed]\n",
    "            X_test = mode2x[mode][\"test\"][seed]\n",
    "            \n",
    "            if not do_projection:\n",
    "                prof_clf,prof_score_dev,prof_score_test = train_classifier(X_train, professions_train, X_dev, professions_dev, X_test, professions_test)\n",
    "                prof_clfs[mode][seed][do_projection] = {\"clf\": prof_clf, \"dev_score\": prof_score_dev, \"test_score\": prof_score_test}\n",
    "                \n",
    "                gender_clf,gender_score_dev,gender_score_test = train_classifier(X_train, z_train, X_dev, z_dev, X_test, z_test)\n",
    "                gender_clfs[mode][seed][do_projection] = {\"clf\": gender_clf, \"dev_score\": gender_score_dev, \"test_score\": gender_score_test}\n",
    "                print(\"here\", gender_score_dev, prof_score_dev)\n",
    "            else:\n",
    "                if mode in [\"linear-adv\", \"mlp-adv\"]: continue\n",
    "                    \n",
    "                prof_clfs[mode][seed][do_projection] = defaultdict(dict)\n",
    "                gender_clfs[mode][seed][do_projection] = defaultdict(dict)\n",
    "                \n",
    "                for projtype in [\"rlace\", \"inlp\"]:\n",
    "                    for rank in [1, 4, 8, 16, 32, 50, 64, 100]:\n",
    "                        print(projtype, rank)\n",
    "                        P = mode2p[mode][seed][projtype][0][rank if projtype == \"rlace\" else rank-1]\n",
    "                        prof_clf,prof_score_dev,prof_score_test = train_classifier(X_train@P, professions_train, X_dev@P, professions_dev, X_test@P, professions_test)\n",
    "                        prof_clfs[mode][seed][do_projection][projtype][rank] = {\"clf\": prof_clf, \"dev_score\": prof_score_dev, \"test_score\": prof_score_test} \n",
    "                        \n",
    "                        gender_clf,gender_score_dev,gender_score_test = train_classifier(X_train@P, z_train, X_dev@P, z_dev, X_test@P, z_test)\n",
    "                        gender_clfs[mode][seed][do_projection][projtype][rank] = {\"clf\": gender_clf, \"dev_score\": gender_score_dev, \"test_score\": gender_score_test}\n",
    "                        print(\"here here\", gender_score_dev, prof_score_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"analysis/gender_clfs.pickle\", \"wb\") as f:\n",
    "    pickle.dump(gender_clfs, f)\n",
    "    \n",
    "with open(\"analysis/prof_clfs.pickle\", \"wb\") as f:\n",
    "    pickle.dump(prof_clfs, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record Classifier Accuracy vs. Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"analysis/gender_clfs.pickle\", \"rb\") as f:\n",
    "    gender_clfs = pickle.load(f)\n",
    "    \n",
    "with open(\"analysis/prof_clfs.pickle\", \"rb\") as f:\n",
    "    prof_clfs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(clf_dict, mode, projtype, do_projection):\n",
    "    d = defaultdict(dict) if do_projection else dict()\n",
    "    num_seeds = 1 if mode == \"freezed\" else 5\n",
    "    idx = list(range(num_seeds))\n",
    "    ranks = [1, 4, 8, 16, 32, 50, 64, 100]\n",
    "    \n",
    "    for seed in range(num_seeds):\n",
    "        if not do_projection:\n",
    "            d[seed] = clf_dict[mode][seed][do_projection][\"test_score\"]\n",
    "        else: \n",
    "            \n",
    "            for rank in ranks:\n",
    "                d[seed][rank] = clf_dict[mode][seed][do_projection][projtype][rank][\"test_score\"]\n",
    "    \n",
    "    try:\n",
    "        df = pd.DataFrame(d)\n",
    "    except:\n",
    "        df = pd.DataFrame({k:[v] for k,v in d.items()}, index = range(len(ranks)))#, index = ranks)\n",
    "    df['avg'] = df.mean(numeric_only=True, axis=1)\n",
    "    df[\"std\"] = df.std(numeric_only=True, axis=1)\n",
    "    df.rename_axis(\"rank\", inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_maj(Y):\n",
    "    \n",
    "    from collections import Counter\n",
    "    c = Counter(Y)\n",
    "    p,q = list(c.values())\n",
    "    return max(p/(p+q), 1 - p/(p+q))\n",
    "\n",
    "def plot(df_rlace, df_inlp, xlabel, ylabel, filename, baseline=None, baseline_label=None):\n",
    "\n",
    "    sn.set()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.rcParams['font.family'] = 'Sans'\n",
    "\n",
    "    df_rlace.plot('rank', 'avg', yerr='std', ax=ax, label=\"RLACE (ours)\", marker=\"*\")\n",
    "    df_inlp.plot('rank', 'avg', yerr='std', ax=ax, label=\"INLP\", marker=\"*\")\n",
    "\n",
    "    plt.ylabel(ylabel, fontsize=18)\n",
    "    plt.xlabel(xlabel, fontsize=18)\n",
    "    if baseline:\n",
    "        ax.axhline(baseline, label=baseline_label, color = \"black\", linestyle=\"--\")\n",
    "\n",
    "    plt.legend(fontsize=18)\n",
    "    #ax.yaxis.grid(color='gray', linestyle=\"-\")\n",
    "    #ax.xaxis.grid(color='gray', linestyle='-')\n",
    "    plt.yticks(fontsize=18)\n",
    "    #plt.xticks(range(1,21,2), fontsize=18)\n",
    "    plt.subplots_adjust(bottom=0.17)\n",
    "    plt.subplots_adjust(left=0.15)\n",
    "    ax.figure.savefig(\"analysis/analysis-results/{}\".format(filename), dpi = 700) \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode2proj2profdf = defaultdict(dict)\n",
    "mode2proj2genderdf = defaultdict(dict)\n",
    "\n",
    "for mode in [\"no-adv\", \"mlp-adv\", \"freezed\", \"linear-adv\"]:\n",
    "        for projtype in [\"rlace\", \"inlp\", \"none\"]:\n",
    "            if (projtype != \"none\") and mode in [\"mlp-adv\", \"linear-adv\"]: continue\n",
    "                \n",
    "            df = create_df(prof_clfs, mode, projtype, True if projtype!=\"none\" else False)\n",
    "            mode2proj2profdf[mode][projtype] = df\n",
    "            df = create_df(gender_clfs, mode, projtype, True if projtype!=\"none\" else False)\n",
    "            mode2proj2genderdf[mode][projtype] = df            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(mode2proj2genderdf[\"no-adv\"][\"rlace\"], mode2proj2genderdf[\"no-adv\"][\"inlp\"], \"Dimensions removed\", \"Post-Projection Accuracy\", \"gender-finetuned.pdf\", \n",
    "     get_maj(z_test),\n",
    "    baseline_label=\"Majority\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(mode2proj2genderdf[\"freezed\"][\"rlace\"], mode2proj2genderdf[\"freezed\"][\"inlp\"], \"Dimensions removed\", \"Post-Projection Accuracy\", \"gender-freezed.pdf\", \n",
    "     get_maj(z_test),\n",
    "    baseline_label=\"Majority\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "0dda8425f5b2686a7d4649dd29b2ea64fce78f14efba812f7700f06d7544e589"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
